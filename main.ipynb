{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, lit, when,expr\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, BooleanType, DoubleType, IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"BreweryApp\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_range_path = './craft_beer_bar_sales/Product_range.csv'\n",
    "transactions_path = './craft_beer_bar_sales/Transactions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = spark.read.csv(product_range_path, header=True)\n",
    "product_df.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in product_df.columns:\n",
    "    col_cnt = product_df.select(column).distinct().count()\n",
    "    print(f\"Count Distinct {column}: {col_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_counts = product_df.select([sum((~col(c).isNull()).cast(\"int\")).alias(c) for c in product_df.columns])\n",
    "not_null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_counts_pandas = not_null_counts.toPandas().transpose()\n",
    "ax = not_null_counts_pandas.plot(kind=\"bar\", stacked=True, legend=False, colormap=\"plasma\")\n",
    "plt.title(\"Product Value Counts in Columns\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Number of Null Values\")\n",
    "plt.axhline(y=product_df.count(), color='red', linestyle='--', label='Upper Limit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = spark.read.csv(transactions_path, header=True)\n",
    "transaction_df.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in transaction_df.columns:\n",
    "    col_cnt = transaction_df.select(column).distinct().count()\n",
    "    print(f\"Count Distinct {column}: {col_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_counts = transaction_df.select([sum((~col(c).isNull()).cast(\"int\")).alias(c) for c in transaction_df.columns])\n",
    "not_null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_counts_pandas = not_null_counts.toPandas().transpose()\n",
    "ax = not_null_counts_pandas.plot(kind=\"bar\", stacked=True, legend=False, colormap=\"plasma\")\n",
    "plt.title(\"Transactions Value Counts in Columns\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Number of Null Values\")\n",
    "plt.axhline(y=transaction_df.count(), color='red', linestyle='--', label='Upper Limit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined DataFrame Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = transaction_df\\\n",
    "    .join(product_df, transaction_df['product_code'] == product_df['Product_code'], how=\"left\")\\\n",
    "        .drop(product_df['Product_code'])\\\n",
    "        .select(\"Date_and_time_of_unloading\",  \"Product_code\",  \"Vendor_code\",  \"Name\",  \"Retail_price\",  \"Base_unit\",  \"Country_of_Origin\",  \"Size\",  \"ABV\",  \"Amount\",  \"Sale_amount\",  \"Discount_amount\",  \"Profit\",  \"Percentage_markup\",  \"Discount_percentage\")\n",
    "sales_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total Product Rows:\", product_df.count())\n",
    "print(\"Total Transactions Rows:\", transaction_df.count())\n",
    "print(\"Total Sales Rows:\", sales_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "inactive_product_count = (\n",
    "    product_df\n",
    "    .join(\n",
    "        transaction_df.select(\"product_code\").distinct(),\n",
    "        on=\"product_code\",\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "    .count()\n",
    ")\n",
    "print(\" Total Number of Products:\", product_df.count())\n",
    "print(\"Inactive List of Products:\", inactive_product_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sales_df.columns:\n",
    "    col_cnt = sales_df.select(column).distinct().count()\n",
    "    print(f\"Count Distinct {column}: {col_cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_counts = sales_df.select([sum((~col(c).isNull()).cast(\"int\")).alias(c) for c in sales_df.columns])\n",
    "print(\"Not Null Count\")\n",
    "not_null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_counts_pandas = not_null_counts.toPandas().transpose()\n",
    "ax = not_null_counts_pandas.plot(kind=\"bar\", stacked=True, legend=False, colormap=\"plasma\")\n",
    "plt.title(\"Sales Value Counts in Columns\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Number of Null Values\")\n",
    "plt.axhline(y=sales_df.count(), color='red', linestyle='--', label='Upper Limit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = sales_df.count()\n",
    "null_percentage_df = sales_df.agg(*[(sum(col(c).isNull().cast(\"int\"))*100 / total_sales).alias(c) for c in sales_df.columns])\n",
    "null_percentage_pandas = null_percentage_df.toPandas().transpose()\n",
    "print(\"Null Percentage\")\n",
    "display(null_percentage_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = sales_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in sales_df.columns])\n",
    "print(\"Null Value Count\")\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sales Product without Retail Price')\n",
    "sales_df.filter(col('Retail_price').isNull()).select('Product_code', 'Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name: Snacks')\n",
    "sales_df.filter(col('Name') == 'Snacks').show(5)\n",
    "print('Vendor_code: Snacks')\n",
    "sales_df.filter(col('Vendor_code') == 'Snacks').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vendor_Code Count\")\n",
    "sales_df.groupBy('Vendor_code').count().orderBy('count', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name: Soft drinks')\n",
    "sales_df.filter(col('Name') == 'Soft drinks').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Snacks & Soft Drinks: Vendor_code & Name\n",
    "sales_df = sales_df.filter(\n",
    "    (col('Vendor_code') != 'Snacks') | \n",
    "    (col('Name') != 'Snacks') \n",
    ")\n",
    "sales_df = sales_df.filter(\n",
    "    (col('Name') != 'Soft drinks')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sales with Vendor_code Null')\n",
    "sales_df.filter(col('Vendor_code').isNull()).show(5)\n",
    "print('Sales with Country_of_Origin Null')\n",
    "sales_df.filter(col('Country_of_Origin').isNull()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sales with Size Null')\n",
    "sales_df.filter(col('Size').isNull()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Null Values from Vendor_Code & Country_of_Oriigin\n",
    "sales_df = sales_df.na.fill(\"Other\",[\"Vendor_code\", \"Country_of_Origin\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unknown Value in Country of Origin\n",
    "sales_df.filter(col('Country_of_Origin') == \"???\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Unknown Value in Country of Origin\n",
    "sales_df = sales_df.withColumn(\"Country_of_Origin\", when(col(\"Country_of_Origin\") == \"???\", \"Other\").otherwise(col(\"Country_of_Origin\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unrequired fields\n",
    "sales_df = sales_df.drop('Percentage_markup', 'Discount_percentage')\n",
    "sales_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Null with 0 for Discount\n",
    "sales_df = sales_df.withColumn(\"Discount_amount\", \\\n",
    "       when(col(\"Discount_amount\").isNull() ,0) \\\n",
    "          .otherwise(col(\"Discount_amount\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = sales_df.withColumn('cal_sale', expr(\"round((Retail_price * Amount)-Discount_amount,2)\"))\\\n",
    "    .select('Retail_price', 'Amount', 'Discount_amount', 'Sale_amount', 'cal_sale')\n",
    "print('Recalculate Sales_Amount')\n",
    "temp_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correct & Incorrect Sales Amount')\n",
    "print(\"Correct: \",)\n",
    "print(\"Incorrect: \",temp_df.filter(col('Sale_amount')!=col('cal_sale')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Correct', 'Miscalculated']\n",
    " \n",
    "data = [\n",
    "    temp_df.filter(col('Sale_amount')==col('cal_sale')).count(),\n",
    "    temp_df.filter(col('Sale_amount')!=col('cal_sale')).count()\n",
    "]\n",
    " \n",
    "fig = plt.figure(figsize =(8, 5))\n",
    "plt.pie(data, labels = labels, startangle = 90, autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Miscalculated Sales Amount Ratio')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Sale_Amount with Actual Formula\n",
    "sales_df = sales_df.withColumn('Sale_amount', expr(\"round((Retail_price * Amount)-Discount_amount,2)\"))\n",
    "sales_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df\\\n",
    "    .withColumn('Entry_date', col('Date_and_time_of_unloading').cast(DateType()))\\\n",
    "    .drop('Date_and_time_of_unloading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df\\\n",
    "    .withColumn('Retail_price', col('Retail_price').cast(DoubleType()))\\\n",
    "    .withColumn('Size', col('Size').cast(DoubleType()))\\\n",
    "    .withColumn('ABV', col('ABV').cast(DoubleType()))\\\n",
    "    .withColumn('Amount', col('Amount').cast(DoubleType()))\\\n",
    "    .withColumn('Sale_amount', col('Sale_amount').cast(DoubleType()))\\\n",
    "    .withColumn('Discount_amount', col('Discount_amount').cast(DoubleType()))\\\n",
    "    .withColumn('Profit', col('Profit').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sales_df.dtypes:\n",
    "    print(column[0],column[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df.withColumnsRenamed({\n",
    "    \"Product_code\": \"pid\",\n",
    "    \"Vendor_code\": \"vendor\",\n",
    "    \"Name\": \"product\",\n",
    "    \"Retail_price\": \"retail_price\",\n",
    "    \"Base_unit\": \"base_unit\",\n",
    "    \"Country_of_Origin\": \"origin_country\",\n",
    "    \"Size\": \"size\",\n",
    "    \"ABV\": \"abv\",\n",
    "    \"Amount\": \"quantity\",\n",
    "    \"Sale_amount\": \"total_sale\",\n",
    "    \"Discount_amount\": \"discount\",\n",
    "    \"Profit\": \"profit\",\n",
    "    \"Entry_date\": \"entry_date\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder Columns\n",
    "columns = sales_df.columns\n",
    "columns.insert(0, columns.pop())\n",
    "sales_df = sales_df.select(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_df.coalesce(1).write.csv(\"output/sales\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.createOrReplaceTempView('sales')\n",
    "spark.sql(\"select * from sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Profit Product of All Time\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pid,\n",
    "    product,\n",
    "    round(sum(profit)) total_profit\n",
    "FROM SALES\n",
    "GROUP BY 1,2\n",
    "ORDER BY 3 DESC\n",
    "LIMIT 10\n",
    "\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 Loss Product of All Time\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pid,\n",
    "    product,\n",
    "    round(sum(profit)) total_loss\n",
    "FROM SALES\n",
    "WHERE profit < 0\n",
    "GROUP BY 1,2\n",
    "ORDER BY 3\n",
    "LIMIT 5\n",
    "\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 Country By Sales\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    origin_country,\n",
    "    CAST(sum(total_sale) AS DECIMAL) total_sale\n",
    "FROM SALES\n",
    "WHERE origin_country <> 'Other'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5\n",
    "\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 Vendor By Sales\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    vendor,\n",
    "    CAST(sum(total_sale) AS DECIMAL) total_sale\n",
    "FROM SALES\n",
    "WHERE vendor <> \"Other\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5\n",
    "\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Discounted Product\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pid,\n",
    "    product,\n",
    "    round(sum(discount)) total_discount\n",
    "FROM SALES\n",
    "GROUP BY 1,2\n",
    "ORDER BY 3 DESC\n",
    "LIMIT 10\n",
    "\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Discounted Product with Profit\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pid,\n",
    "    product,\n",
    "    round(sum(profit)) total_profit,\n",
    "    round(sum(discount)) total_discount\n",
    "FROM SALES\n",
    "WHERE discount IS NOT NULL\n",
    "GROUP BY 1,2\n",
    "ORDER BY 4 DESC,3 DESC\n",
    "LIMIT 10\n",
    "\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Profitable and Sales Cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_data = sales_df\\\n",
    "    .filter(col('profit').isNotNull())\\\n",
    "    .groupBy('product')\\\n",
    "    .agg(sum(\"total_sale\").alias(\"total_sale\"), sum(\"profit\").alias(\"profit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['total_sale', 'profit']\n",
    "assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "transformed_data = assembler.transform(beer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans( k=4 , seed = 42 , featuresCol = \"features\")\n",
    "model = kmeans.fit(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(transformed_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pd = predictions.select(\"prediction\", \"total_sale\", \"profit\").toPandas()\n",
    "predictions_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions_pd[\"total_sale\"],predictions_pd[\"profit\"],\n",
    "           c = predictions_pd[\"prediction\"], cmap = 'viridis' )\n",
    "plt.xlabel(\"total_sale\")\n",
    "plt.ylabel(\"profit\")\n",
    "plt.title(\"K-means Clustering of Beer Products\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = predictions.drop('features')\n",
    "# save_df.coalesce(1).write.csv(\"output/clustering\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator(featuresCol='features', predictionCol='prediction', metricName='silhouette')\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
